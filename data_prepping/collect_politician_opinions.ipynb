{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/projects/kokkai_analysis/data_prepping/data/data_repr_new\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from params.paths import ROOT_DIR, CHROMEDRIVER_PATH\n",
    "from api_requests.meeting_convo_collector import MeetingConvoCollector\n",
    "\n",
    "from file_handling.file_read_writer import read_json, write_json, create_dir, write_file\n",
    "\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', 'data_repr_new')\n",
    "create_dir(OUTPUT_DIR)\n",
    "print(os.path.abspath(OUTPUT_DIR))\n",
    "LOWER_HOUSE_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'data_shugiin')\n",
    "UPPER_HOUSE_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'data_sangiin')\n",
    "\n",
    "#reading the reprentative data for lower and upper house\n",
    "lower_repr_dir = os.path.join(LOWER_HOUSE_DATA_DIR, 'repr_list')\n",
    "lower_repr_file = os.listdir(lower_repr_dir)[0]\n",
    "lower_house_meeting_dict = read_json(os.path.join(lower_repr_dir, lower_repr_file))\n",
    "\n",
    "upper_repr_dir = os.path.join(UPPER_HOUSE_DATA_DIR, 'repr_list')\n",
    "upper_repr_file = os.listdir(upper_repr_dir)[0]\n",
    "upper_house_meeting_dict = read_json(os.path.join(upper_repr_dir, upper_repr_file))\n",
    "repr_dict = lower_house_meeting_dict['reprs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repr_name(repr_name):\n",
    "\trepr_name = re.sub('\\s|君|\\[(.*?)\\]', '', repr_name)\n",
    "\treturn repr_name\n",
    "\n",
    "def remove_duplicate_speeches(speeches):\n",
    "\tids = []\n",
    "\tunique_speeches = []\n",
    "\tfor speech in speeches:\n",
    "\t\tif speech['speech_id'] not in ids:\n",
    "\t\t\tids.append(speech['speech_id'])\n",
    "\t\t\tunique_speeches.append(speech)\n",
    "\treturn unique_speeches\n",
    "\n",
    "\n",
    "class ReprTopicOpinionCollector:\n",
    "\tdef __init__(self):\n",
    "\t\tself.mcc = MeetingConvoCollector(\"https://kokkai.ndl.go.jp/api/speech?\")\n",
    "\t\tself.topic_dict = read_json(os.path.join(ROOT_DIR, 'resource','search_words_for_topics.json'))\n",
    "\n",
    "\t\tself.model_name = \"kkatodus/jp-speech-classifier\"\n",
    "\t\tself.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "\t\tself.model = BertForSequenceClassification.from_pretrained(self.model_name)\n",
    "\n",
    "\t\tlog_dir = os.path.join(ROOT_DIR, 'logs')\n",
    "\t\tcreate_dir(log_dir)\n",
    "\t\tlogging.basicConfig(filename=os.path.join(log_dir, 'politician_opinion_collection.log'), filemode='w', format='%(asctime)s - %(message)s')\n",
    "\t\tself.logger = logging.getLogger()\n",
    "\t\tself.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\t\tself.current_party = None\n",
    "\t\tself.current_repr = None\n",
    "\t\tself.current_topic = None\n",
    "\t\tself.current_search_words = None\n",
    "\t\tself.current_search_word = None\n",
    "\t\tself.current_speeches_dict_for_repr_for_topic = []\n",
    "\t\n",
    "\tdef check_search_words_in_string(self, string):\n",
    "\t\tfor search_word in self.current_search_words:\n",
    "\t\t\tif search_word in string:\n",
    "\t\t\t\treturn True\n",
    "\t\treturn False\n",
    "\n",
    "\tdef extract_opinions(self, speech, target_class = ['意見文']):\n",
    "\t\tspeech_segments = speech.split('。')\n",
    "\t\tencoded = self.tokenizer(speech_segments, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tlogits = self.model(**encoded).logits\n",
    "\t\tpredicted_class_id = logits.argmax(dim=1)\n",
    "\t\tclasses = [self.model.config.id2label[pred_id.item()] for pred_id in list(predicted_class_id)]\n",
    "\t\textracted_segments = []\n",
    "\t\tfor idx, (sentence, pred_class) in enumerate(zip(speech_segments, classes)):\n",
    "\t\t\tif pred_class in target_class and self.check_search_words_in_string(sentence):\n",
    "\t\t\t\textracted_segments.append(sentence)\n",
    "\t\tif len(extracted_segments) == 0:\n",
    "\t\t\tself.logger.info(f\"no opinion found for in speech segments with search word {self.current_search_word}\\n\\n\\n\")\n",
    "\t\t\n",
    "\t\treturn extracted_segments\n",
    "\n",
    "\tdef iterate_speeches(self, record):\n",
    "\t\toutput_array = []\n",
    "\t\tif record['numberOfRecords'] == 0:\n",
    "\t\t\treturn output_array\n",
    "\t\tfor speech in record['speechRecord']:\n",
    "\t\t\tspeech_id = speech['speechID']\n",
    "\t\t\thouse_name = speech['nameOfHouse']\n",
    "\t\t\tmeeting_name = speech['nameOfMeeting']\n",
    "\t\t\tdate = speech['date']\n",
    "\t\t\tspeech_text = speech['speech']\n",
    "\t\t\tspeech_url = speech['speechURL']\n",
    "\t\t\tspeaker_group = speech['speakerGroup']\n",
    "\t\t\textracted_opinions = self.extract_opinions(speech_text)\n",
    "\t\t\tif len(extracted_opinions) > 0:\n",
    "\t\t\t\t# speech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_text': speech_text, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\n",
    "\t\t\t\tspeech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\n",
    "\t\t\t\toutput_array.append(speech_dict)\n",
    "\t\treturn output_array\n",
    "\n",
    "\tdef add_processed_speeches(self):\n",
    "\t\tconditions_list = [f\"any={self.current_search_word}\",f\"speaker={self.current_repr_name}\",'recordPacking=json','maximumRecords=50']\n",
    "\t\tself.logger.info(f\"searching for {self.current_repr_name} with search word {self.current_search_word} in {self.current_topic}\")\n",
    "\t\tstart_point = 1\n",
    "\t\twhile True:\n",
    "\t\t\tif start_point is None:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tspeeches, start_point = self.mcc.make_one_request(conditions_list, starting_point=start_point)\n",
    "\t\t\tspeeches = self.iterate_speeches(speeches)\n",
    "\t\t\tif len(speeches) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tself.current_speeches_dict_for_repr_for_topic.extend(speeches)\n",
    "\t\n",
    "\n",
    "\tdef collect(self):\n",
    "\t\tfor party in repr_dict.keys():\n",
    "\t\t\tself.current_party = party\n",
    "\t\t\tfor repr in repr_dict[party]:\n",
    "\t\t\t\tself.current_repr = repr\n",
    "\t\t\t\tself.current_repr_name = clean_repr_name(repr['name'])\n",
    "\t\t\t\tfor topic, search_words in self.topic_dict.items():\n",
    "\t\t\t\t\tself.current_topic = topic\n",
    "\t\t\t\t\tself.current_search_words = search_words\n",
    "\t\t\t\t\trepr_topic_dir = os.path.join(OUTPUT_DIR, party, self.current_repr_name, topic)\n",
    "\t\t\t\t\ttopic_file_path = os.path.join(repr_topic_dir, 'opinions.json')\n",
    "\t\t\t\t\tif os.path.exists(topic_file_path):\n",
    "\t\t\t\t\t\tprint('Already collected speeches for',party, self.current_repr_name, topic)\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tcreate_dir(repr_topic_dir)\n",
    "\t\t\t\t\tprint(f\"Collecting speeches for {self.current_repr_name}\")\n",
    "\t\t\t\t\tfor search_word in search_words:\n",
    "\t\t\t\t\t\tself.current_search_word = search_word\n",
    "\t\t\t\t\t\tself.add_processed_speeches()\n",
    "\t\t\t\t\tif len(self.current_speeches_dict_for_repr_for_topic) > 0:\n",
    "\t\t\t\t\t\tself.current_speeches_dict_for_repr_for_topic = remove_duplicate_speeches(self.current_speeches_dict_for_repr_for_topic)\n",
    "\t\t\t\t\t\tsorted_speeches = sorted(self.current_speeches_dict_for_repr_for_topic, key=lambda k: k['date'], reverse=True)\n",
    "\t\t\t\t\t\tout_dict = {'party': self.current_party, 'repr_name': self.current_repr_name, 'topic': self.current_topic, 'search_words': self.current_search_words, 'speeches': sorted_speeches}\n",
    "\t\t\t\t\t\twrite_json(out_dict, topic_file_path)\n",
    "\t\t\t\t\tself.current_speeches_dict_for_repr_for_topic = []\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to collect opinion based sentences for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speeches for 逢沢一郎\n",
      "https://kokkai.ndl.go.jp/api/speech?startRecord=1&any=自衛隊&speaker=逢沢一郎&recordPacking=json&maximumRecords=50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m repr_topic_opinion_collector \u001b[39m=\u001b[39m ReprTopicOpinionCollector()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m repr_topic_opinion_collector\u001b[39m.\u001b[39;49mcollect()\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39mfor\u001b[39;00m search_word \u001b[39min\u001b[39;00m search_words:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_search_word \u001b[39m=\u001b[39m search_word\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=109'>110</a>\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_processed_speeches()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_speeches_dict_for_repr_for_topic) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=111'>112</a>\u001b[0m \tsorted_speeches \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(remove_duplicate_speeches(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_speeches_dict_for_repr_for_topic), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m k: k[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m \t\u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m speeches, start_point \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcc\u001b[39m.\u001b[39mmake_one_request(conditions_list, starting_point\u001b[39m=\u001b[39mstart_point)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m speeches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterate_speeches(speeches)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(speeches) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m \t\u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m speech_url \u001b[39m=\u001b[39m speech[\u001b[39m'\u001b[39m\u001b[39mspeechURL\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m speaker_group \u001b[39m=\u001b[39m speech[\u001b[39m'\u001b[39m\u001b[39mspeakerGroup\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m extracted_opinions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_opinions(speech_text)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(extracted_opinions) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \t\u001b[39m# speech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_text': speech_text, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \tspeech_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mspeech_id\u001b[39m\u001b[39m'\u001b[39m: speech_id, \u001b[39m'\u001b[39m\u001b[39mhouse_name\u001b[39m\u001b[39m'\u001b[39m: house_name, \u001b[39m'\u001b[39m\u001b[39mmeeting_name\u001b[39m\u001b[39m'\u001b[39m: meeting_name, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m: date, \u001b[39m'\u001b[39m\u001b[39mspeech_url\u001b[39m\u001b[39m'\u001b[39m: speech_url, \u001b[39m'\u001b[39m\u001b[39mspeaker_group\u001b[39m\u001b[39m'\u001b[39m:speaker_group,\u001b[39m'\u001b[39m\u001b[39mextracted_opinions\u001b[39m\u001b[39m'\u001b[39m: extracted_opinions}\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(speech_segments, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \tlogits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded)\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m predicted_class_id \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m classes \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label[pred_id\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m pred_id \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(predicted_class_id)]\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1563\u001b[0m     input_ids,\n\u001b[1;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1572\u001b[0m )\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    540\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    549\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 550\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:462\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 462\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    463\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    464\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "repr_topic_opinion_collector = ReprTopicOpinionCollector()\n",
    "repr_topic_opinion_collector.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating summary json to record topics for each politicians and how many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a summary json for the repr opinions data\n",
    "summary_dict = {'reprs':{}}\n",
    "for party in repr_dict.keys():\n",
    "\tsummary_dict['reprs'][party] = {}\n",
    "\tfor repr in repr_dict[party]:\n",
    "\t\trepr_name = repr['name']\n",
    "\t\trepr_name = clean_repr_name(repr_name)\n",
    "\t\trepr_dir_path = os.path.join(OUTPUT_DIR,party, repr_name)\n",
    "\t\tif not os.path.exists(repr_dir_path):\n",
    "\t\t\tcontinue\n",
    "\t\ttags = [dirname for dirname in os.listdir(repr_dir_path)]\n",
    "\t\tif len(tags) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tsummary_dict['reprs'][party][repr_name] = {}\n",
    "\t\tsummary_dict['reprs'][party][repr_name]['tags'] = tags\n",
    "\t\tsummary_dict['reprs'][party][repr_name]['number_of_files'] = {}\n",
    "\t\tfor tag in tags:\n",
    "\t\t\ttopic_dir = os.path.join(repr_dir_path, tag)\n",
    "\t\t\tnumber_of_files = len(os.listdir(topic_dir))\n",
    "\t\t\tsummary_dict['reprs'][party][repr_name]['number_of_files'][tag] = number_of_files\n",
    "write_json(summary_dict, os.path.join(OUTPUT_DIR, 'summary.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kokkai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
