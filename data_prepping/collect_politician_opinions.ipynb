{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/projects/kokkai_analysis/data_prepping/data/data_repr_upper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from params.paths import ROOT_DIR, CHROMEDRIVER_PATH\n",
    "from api_requests.meeting_convo_collector import MeetingConvoCollector\n",
    "\n",
    "from file_handling.file_read_writer import read_json, write_json, create_dir, write_file\n",
    "\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', 'data_repr_upper')\n",
    "create_dir(OUTPUT_DIR)\n",
    "print(os.path.abspath(OUTPUT_DIR))\n",
    "LOWER_HOUSE_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'data_shugiin')\n",
    "UPPER_HOUSE_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'data_sangiin')\n",
    "\n",
    "#reading the reprentative data for lower and upper house\n",
    "lower_repr_dir = os.path.join(LOWER_HOUSE_DATA_DIR, 'repr_list')\n",
    "lower_repr_file = os.listdir(lower_repr_dir)[0]\n",
    "lower_house_meeting_dict = read_json(os.path.join(lower_repr_dir, lower_repr_file))\n",
    "lower_repr_dict = lower_house_meeting_dict['reprs']\n",
    "\n",
    "upper_repr_dir = os.path.join(UPPER_HOUSE_DATA_DIR, 'repr_list')\n",
    "upper_repr_file = os.listdir(upper_repr_dir)[0]\n",
    "upper_house_meeting_dict = read_json(os.path.join(upper_repr_dir, upper_repr_file))\n",
    "upper_repr_dict = upper_house_meeting_dict['reprs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repr_name(repr_name):\n",
    "\trepr_name = re.sub('\\s|君|\\[(.*?)\\]', '', repr_name)\n",
    "\treturn repr_name\n",
    "\n",
    "def remove_duplicate_speeches(speeches):\n",
    "\tids = []\n",
    "\tunique_speeches = []\n",
    "\tfor speech in speeches:\n",
    "\t\tif speech['speech_id'] not in ids:\n",
    "\t\t\tids.append(speech['speech_id'])\n",
    "\t\t\tunique_speeches.append(speech)\n",
    "\treturn unique_speeches\n",
    "\n",
    "\n",
    "class ReprTopicOpinionCollector:\n",
    "\tdef __init__(self, house='lower'):\n",
    "\t\tself.mcc = MeetingConvoCollector(\"https://kokkai.ndl.go.jp/api/speech?\")\n",
    "\t\tself.topic_dict = read_json(os.path.join(ROOT_DIR, 'resource','experiment_config.json'))\n",
    "\t\tif house == 'lower':\n",
    "\t\t\tself.repr_dict = lower_repr_dict\n",
    "\t\telif house == 'upper':\n",
    "\t\t\tself.repr_dict = upper_repr_dict\n",
    "\n",
    "\t\tself.model_name = \"kkatodus/jp-speech-classifier\"\n",
    "\t\tself.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "\t\tself.model = BertForSequenceClassification.from_pretrained(self.model_name)\n",
    "\n",
    "\t\tlog_dir = os.path.join(ROOT_DIR, 'logs')\n",
    "\t\tcreate_dir(log_dir)\n",
    "\t\tlogging.basicConfig(filename=os.path.join(log_dir, 'politician_opinion_collection.log'), filemode='w', format='%(asctime)s - %(message)s')\n",
    "\t\tself.logger = logging.getLogger()\n",
    "\t\tself.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\t\tself.current_party = None\n",
    "\t\tself.current_repr = None\n",
    "\t\tself.current_topic = None\n",
    "\t\tself.current_search_words = None\n",
    "\t\tself.current_search_word = None\n",
    "\t\tself.current_speeches_dict_for_repr_for_topic = []\n",
    "\t\n",
    "\tdef check_search_words_in_string(self, string):\n",
    "\t\tfor search_word in self.current_search_words:\n",
    "\t\t\tif search_word in string:\n",
    "\t\t\t\treturn True\n",
    "\t\treturn False\n",
    "\t\n",
    "\tdef create_mini_batches_from_sentences(self, sentences, batch_size=100):\n",
    "\t\tmini_batches = []\n",
    "\t\tfor i in range(0, len(sentences), batch_size):\n",
    "\t\t\tmini_batches.append(sentences[i:i+batch_size])\n",
    "\t\treturn mini_batches\n",
    "\n",
    "\tdef extract_opinions(self, speech, target_class = ['意見文']):\n",
    "\t\tspeech_segments = speech.split('。')\n",
    "\t\tsegment_batches = self.create_mini_batches_from_sentences(speech_segments)\n",
    "\t\tself.logger.info(f\"Created {len(segment_batches)} speech segment batches of length {[len(batch) for batch in segment_batches]}\")\n",
    "\t\textracted_segments = []\n",
    "\t\tfor idx, segment_batch in enumerate(segment_batches):\n",
    "\t\t\tself.logger.info(f\"Encoding {len(segment_batch)} speech segments\")\n",
    "\t\t\tencoded = self.tokenizer(segment_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tself.logger.info(f\"Predicting {len(segment_batch)} speech segments\")\n",
    "\t\t\t\tlogits = self.model(**encoded).logits\n",
    "\t\t\tpredicted_class_id = logits.argmax(dim=1)\n",
    "\t\t\tclasses = [self.model.config.id2label[pred_id.item()] for pred_id in list(predicted_class_id)]\n",
    "\t\t\tfor idx, (sentence, pred_class) in enumerate(zip(segment_batch, classes)):\n",
    "\t\t\t\tif pred_class in target_class and self.check_search_words_in_string(sentence):\n",
    "\t\t\t\t\textracted_segments.extend([sentence])\n",
    "\t\tif len(extracted_segments) == 0:\n",
    "\t\t\tself.logger.info(f\"no opinion found for in speech segments with search word {self.current_search_word}\\n\\n\\n\")\n",
    "\t\t\n",
    "\t\treturn extracted_segments\n",
    "\n",
    "\tdef iterate_speeches(self, record):\n",
    "\t\toutput_array = []\n",
    "\t\tif record['numberOfRecords'] == 0:\n",
    "\t\t\treturn output_array\n",
    "\t\tfor idx, speech in enumerate(record['speechRecord']):\n",
    "\t\t\tself.logger.info(f\"Working on {idx}/{len(record['speechRecord'])} speech record\")\n",
    "\t\t\tspeech_id = speech['speechID']\n",
    "\t\t\thouse_name = speech['nameOfHouse']\n",
    "\t\t\tmeeting_name = speech['nameOfMeeting']\n",
    "\t\t\tdate = speech['date']\n",
    "\t\t\tspeech_text = speech['speech']\n",
    "\t\t\tspeech_url = speech['speechURL']\n",
    "\t\t\tspeaker_group = speech['speakerGroup']\n",
    "\t\t\textracted_opinions = self.extract_opinions(speech_text)\n",
    "\t\t\tif len(extracted_opinions) > 0:\n",
    "\t\t\t\t# speech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_text': speech_text, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\n",
    "\t\t\t\tspeech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\n",
    "\t\t\t\toutput_array.append(speech_dict)\n",
    "\t\treturn output_array\n",
    "\n",
    "\tdef add_processed_speeches(self):\n",
    "\t\tconditions_list = [f\"any={self.current_search_word}\",f\"speaker={self.current_repr_name}\",'recordPacking=json','maximumRecords=50']\n",
    "\t\tstart_point = 1\n",
    "\t\tself.logger.info(f\"searching for {self.current_repr_name} with search word {self.current_search_word} in {self.current_topic} with start point {start_point}\")\n",
    "\n",
    "\t\twhile True:\n",
    "\t\t\tif start_point is None:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tself.logger.info(f\"Making one request with start point {start_point}\")\n",
    "\t\t\tspeech_records, start_point = self.mcc.make_one_request(conditions_list, starting_point=start_point)\n",
    "\t\t\tself.logger.info(f\"Got {speech_records['numberOfRecords']} speeches records\")\n",
    "\t\t\tprocessed_speeches = self.iterate_speeches(speech_records)\n",
    "\t\t\tif len(processed_speeches) == 0:\n",
    "\t\t\t\tself.logger.info(\"No processed_speeches found for speech record\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tself.current_speeches_dict_for_repr_for_topic.extend(processed_speeches)\n",
    "\t\t\tself.logger.info(f\"Added {len(processed_speeches)} speeches to the list with {len(self.current_speeches_dict_for_repr_for_topic)} speeches in total\")\n",
    "\n",
    "\tdef collect(self):\n",
    "\t\tfor party in self.repr_dict.keys():\n",
    "\t\t\tself.current_party = party\n",
    "\t\t\tfor repr in self.repr_dict[party]:\n",
    "\t\t\t\tself.current_repr = repr\n",
    "\t\t\t\tself.current_repr_name = clean_repr_name(repr['name'])\n",
    "\t\t\t\tfor topic_config in self.topic_dict:\n",
    "\t\t\t\t\ttopic = topic_config['topic_name']\n",
    "\t\t\t\t\tsearch_words = topic_config['search_words']\n",
    "\t\t\t\t\tself.current_topic = topic\n",
    "\t\t\t\t\tself.current_search_words = search_words\n",
    "\t\t\t\t\trepr_topic_dir = os.path.join(OUTPUT_DIR, party, self.current_repr_name, topic)\n",
    "\t\t\t\t\ttopic_file_path = os.path.join(repr_topic_dir, 'opinions.json')\n",
    "\t\t\t\t\tif os.path.exists(topic_file_path):\n",
    "\t\t\t\t\t\tprint('Already collected speeches for',party, self.current_repr_name, topic)\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tprint(f\"Collecting speeches for {self.current_repr_name} with topic {self.current_topic}\")\n",
    "\t\t\t\t\tfor search_word in search_words:\n",
    "\t\t\t\t\t\tself.current_search_word = search_word\n",
    "\t\t\t\t\t\tself.add_processed_speeches()\n",
    "\t\t\t\t\tcreate_dir(repr_topic_dir)\n",
    "\t\t\t\t\tif len(self.current_speeches_dict_for_repr_for_topic) > 0:\n",
    "\t\t\t\t\t\tself.current_speeches_dict_for_repr_for_topic = remove_duplicate_speeches(self.current_speeches_dict_for_repr_for_topic)\n",
    "\t\t\t\t\t\tsorted_speeches = sorted(self.current_speeches_dict_for_repr_for_topic, key=lambda k: k['date'], reverse=True)\n",
    "\t\t\t\t\t\tout_dict = {'party': self.current_party, 'repr_name': self.current_repr_name, 'topic': self.current_topic, 'search_words': self.current_search_words, 'speeches': sorted_speeches}\n",
    "\t\t\t\t\t\tself.logger.info(f\"writing speeches for {self.current_repr_name} with search word {self.current_search_word} in {self.current_topic}\")\n",
    "\t\t\t\t\t\twrite_json(out_dict, topic_file_path)\n",
    "\t\t\t\t\t\tself.logger.info(f'Finished writing file')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\twrite_json({}, topic_file_path)\n",
    "\t\t\t\t\t\tself.logger.info(f\"no speeches found for {self.current_repr_name} with search word {self.current_search_word} in {self.current_topic}\")\n",
    "\t\t\t\t\tself.current_speeches_dict_for_repr_for_topic = []\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to collect opinion based sentences for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already collected speeches for 自民 足立敏之 防衛\n",
      "Already collected speeches for 自民 足立敏之 少子化\n",
      "Already collected speeches for 自民 足立敏之 LGBTQ\n",
      "Already collected speeches for 自民 足立敏之 原発\n",
      "Already collected speeches for 自民 足立敏之 気候変動\n",
      "Collecting speeches for 足立敏之 with topic 経済対策\n",
      "https://kokkai.ndl.go.jp/api/speech?startRecord=1&any=経済対策&speaker=足立敏之&recordPacking=json&maximumRecords=50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m repr_topic_opinion_collector \u001b[39m=\u001b[39m ReprTopicOpinionCollector(house\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m repr_topic_opinion_collector\u001b[39m.\u001b[39;49mcollect()\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mfor\u001b[39;00m search_word \u001b[39min\u001b[39;00m search_words:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_search_word \u001b[39m=\u001b[39m search_word\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_processed_speeches()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m create_dir(repr_topic_dir)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_speeches_dict_for_repr_for_topic) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m speech_records, start_point \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcc\u001b[39m.\u001b[39mmake_one_request(conditions_list, starting_point\u001b[39m=\u001b[39mstart_point)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{\u001b[39;00mspeech_records[\u001b[39m'\u001b[39m\u001b[39mnumberOfRecords\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m speeches records\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m processed_speeches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterate_speeches(speech_records)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(processed_speeches) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mNo processed_speeches found for speech record\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m speech_url \u001b[39m=\u001b[39m speech[\u001b[39m'\u001b[39m\u001b[39mspeechURL\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m speaker_group \u001b[39m=\u001b[39m speech[\u001b[39m'\u001b[39m\u001b[39mspeakerGroup\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m extracted_opinions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_opinions(speech_text)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(extracted_opinions) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m \t\u001b[39m# speech_dict = {'speech_id': speech_id, 'house_name': house_name, 'meeting_name': meeting_name, 'date': date, 'speech_text': speech_text, 'speech_url': speech_url, 'speaker_group':speaker_group,'extracted_opinions': extracted_opinions}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \tspeech_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mspeech_id\u001b[39m\u001b[39m'\u001b[39m: speech_id, \u001b[39m'\u001b[39m\u001b[39mhouse_name\u001b[39m\u001b[39m'\u001b[39m: house_name, \u001b[39m'\u001b[39m\u001b[39mmeeting_name\u001b[39m\u001b[39m'\u001b[39m: meeting_name, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m: date, \u001b[39m'\u001b[39m\u001b[39mspeech_url\u001b[39m\u001b[39m'\u001b[39m: speech_url, \u001b[39m'\u001b[39m\u001b[39mspeaker_group\u001b[39m\u001b[39m'\u001b[39m:speaker_group,\u001b[39m'\u001b[39m\u001b[39mextracted_opinions\u001b[39m\u001b[39m'\u001b[39m: extracted_opinions}\n",
      "\u001b[1;32m/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(segment_batch)\u001b[39m}\u001b[39;00m\u001b[39m speech segments\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \tlogits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded)\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m predicted_class_id \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/projects/kokkai_analysis/data_prepping/collect_politician_opinions.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m classes \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label[pred_id\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m pred_id \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(predicted_class_id)]\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1563\u001b[0m     input_ids,\n\u001b[1;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1572\u001b[0m )\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    496\u001b[0m         hidden_states,\n\u001b[1;32m    497\u001b[0m         attention_mask,\n\u001b[1;32m    498\u001b[0m         head_mask,\n\u001b[1;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:434\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    426\u001b[0m         hidden_states,\n\u001b[1;32m    427\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m         output_attentions,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[0;32m--> 434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:384\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 384\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    385\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    386\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/kokkai_analysis/data_prepping/kokkai_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "repr_topic_opinion_collector = ReprTopicOpinionCollector(house=\"upper\")\n",
    "repr_topic_opinion_collector.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating summary json to record topics for each politicians and how many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a summary json for the repr opinions data\n",
    "summary_dict = {'reprs':{}}\n",
    "for party in repr_dict.keys():\n",
    "\tsummary_dict['reprs'][party] = {}\n",
    "\tfor repr in repr_dict[party]:\n",
    "\t\trepr_name = repr['name']\n",
    "\t\trepr_name = clean_repr_name(repr_name)\n",
    "\t\trepr_dir_path = os.path.join(OUTPUT_DIR,party, repr_name)\n",
    "\t\tif not os.path.exists(repr_dir_path):\n",
    "\t\t\tcontinue\n",
    "\t\ttags = [dirname for dirname in os.listdir(repr_dir_path) if read_json(os.path.join(repr_dir_path, dirname, 'opinions.json')) != {}]\n",
    "\t\tif len(tags) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tsummary_dict['reprs'][party][repr_name] = {}\n",
    "\t\tsummary_dict['reprs'][party][repr_name]['tags'] = tags\n",
    "\t\tsummary_dict['reprs'][party][repr_name]['number_of_files'] = {}\n",
    "\t\tfor tag in tags:\n",
    "\t\t\ttopic_dir = os.path.join(repr_dir_path, tag)\n",
    "\t\t\tnumber_of_files = len(os.listdir(topic_dir))\n",
    "\t\t\tsummary_dict['reprs'][party][repr_name]['number_of_files'][tag] = number_of_files\n",
    "write_json(summary_dict, os.path.join(OUTPUT_DIR, 'summary.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kokkai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
