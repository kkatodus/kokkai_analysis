{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from scrape.general_scraper import GeneralScraper\n",
    "from selenium.webdriver.common.by import By\n",
    "import openai\n",
    "from secret_keys.api_keys import OPENAI_API_KEY\n",
    "from file_handling.file_read_writer import read_json, write_json, create_dir\n",
    "from params.paths import ROOT_DIR\n",
    "from logger.Logger import Logger\n",
    "from json import JSONDecodeError\n",
    "RESOURCE_DIR = os.path.join(ROOT_DIR, 'resource')\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "LOCAL_DATA_DIR = os.path.join(DATA_DIR, 'data_local_gov')\n",
    "LOCAL_GOV_MEMBER_DIR = os.path.join(LOCAL_DATA_DIR, 'members')\n",
    "os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(LOCAL_GOV_MEMBER_DIR, exist_ok=True)\n",
    "logger = Logger(os.path.join(LOCAL_DATA_DIR, 'log.txt'))\n",
    "\n",
    "gs = GeneralScraper(firefox=True)\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:512'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-KwrqfnvZUjabTOAFL3QUAhk2\"\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 63 (2309060617.py, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 64\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'else' statement on line 63\n"
     ]
    }
   ],
   "source": [
    "def gpt(content):\n",
    "\tsys_prompt = \"あなたはこれからユーザーからもらうテキストをJSONデータに変換するアシスタントです。\"\n",
    "\tuser_prompt = '以下のテキストからすべての議員の情報を略すことなく完全な辞書のリスト形式で取得してください。結果はJSON形式で返してください。抽出する情報は名前（漢字）、名前（フリガナ）、会派、年齢、所属委員会、名前から推定される性別、です。\\n'\n",
    "\tformat_prompt = '出力フォーマットは次のようにしてください。\\n [ {\"name_kana\":, \"name_kanji\":, \"party\":, \"age\":, \"gender\":, \"commitee\":[], \"term\":, \"district\":, }, { }, { }, ... ]\\n'\n",
    "\tprint('Sending to GPT')\n",
    "\tresponse = openai.ChatCompletion.create(\n",
    "\t\t\tmodel=\"gpt-3.5-turbo-1106\",\n",
    "\t\t\tmessages=[\n",
    "\t\t\t\t{\"role\": \"system\", \"content\":sys_prompt},\n",
    "\t\t\t\t{\"role\": \"user\", \"content\": user_prompt},\n",
    "\t\t\t\t{\"role\": \"user\", \"content\": format_prompt},\n",
    "\t\t\t\t{'role': \"user\", \"content\": content},\n",
    "\t\t\t],\n",
    "\t\t\tresponse_format= { \"type\":\"json_object\" },\n",
    "\t\t\ttemperature=1,\n",
    "\t\t)\n",
    "\ttry:\n",
    "\t\tresponse_content = json.loads(response.choices[0].message.content)\n",
    "\t\treturn response_content\n",
    "\texcept (JSONDecodeError, UnicodeEncodeError):\n",
    "\t\tprint('failed to parse json')\n",
    "\t\tlogger.write(f\"Failed to parse json: {response_content}\\n\")\n",
    "\n",
    "def handle_reprs_on_multiple_pages(city_dict):\n",
    "\toutput = []\n",
    "\tfor url in city_dict['urls']:\n",
    "\t\tgs.get_url(url)\n",
    "\t\tindep_repr_page_links = gs.get_site_components_by(By.XPATH, city_dict['ind_reprs_xpath'])\n",
    "\t\tlinks = [link.get_attribute('href') for link in indep_repr_page_links]\n",
    "\t\tprint(\"Getting independant links\")\n",
    "\t\tfor link in links:\n",
    "\t\t\tprint(\"getting link\", link)\n",
    "\t\t\tgs.get_url(link)\n",
    "\t\t\trepr_info_component = gs.get_site_components_by(By.XPATH, city_dict['ind_reprs_info_xpath'])\n",
    "\t\t\trepr_info = repr_info_component[0].text\n",
    "\t\t\tresponse = gpt(repr_info)\n",
    "\t\t\tif 'members' in response.keys():\n",
    "\t\t\t\toutput += response['members']\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.append(response)\n",
    "\treturn output\n",
    "\n",
    "def handle_reprs_on_single_page(city_dict, city_name):\n",
    "\toutput = []\n",
    "\tfor url in city_dict['urls']:\n",
    "\t\tprint('getting', url)\n",
    "\t\ttry:\n",
    "\t\t\tif not url == gs.driver.current_url:\n",
    "\t\t\t\tgs.get_url(url)\n",
    "\t\texcept:\n",
    "\t\t\tprint('failed to get url', url)\n",
    "\t\t\tlogger.write(f\"Could not get {city_name} : {url}\\n\")\n",
    "\t\ttry:\n",
    "\t\t\treprs_component = gs.get_site_components_by(By.XPATH, city_dict['reprs_xpath'])\n",
    "\t\texcept:\n",
    "\t\t\tlogger.write(f\"Check xpath for {city_name} : {city_dict['reprs_xpath']} : {url}\\n\")\n",
    "\t\tif len(reprs_component) > 0:\n",
    "\t\t\tall_text = reprs_component[0].text\n",
    "\t\t\tprint(f\"Extracted all text for {city_name} : {url}\")\n",
    "\t\t\tresponse = gpt(all_text)\n",
    "\t\t\tif 'members' in response.keys():\n",
    "\t\t\t\toutput += response[\"members\"]\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.append(response)\n",
    "\t\telse:\n",
    "\t\t\tprint('No reprs found on this page.')\n",
    "\t\t\tlogger.write(f\"No reprs found on this page. {city_name} : {url}\\n\")\n",
    "\treturn output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 北海道　岩見沢市 data [1]\n",
      "Getting 北海道　美唄市 data [1]\n",
      "Getting 北海道　芦別市 data [1]\n",
      "Getting 北海道　江別市 data [1]\n",
      "getting https://www.city.ebetsu.hokkaido.jp/site/gikai/2002.html\n",
      "Extracted all text for 北海道　江別市 : https://www.city.ebetsu.hokkaido.jp/site/gikai/2002.html\n",
      "Sending to GPT\n",
      "writing json\n",
      "Getting 北海道　赤平市 data [1]\n",
      "Getting 北海道　紋別市 data [1]\n",
      "getting https://mombetsu.jp/gikai/member/\n",
      "Extracted all text for 北海道　紋別市 : https://mombetsu.jp/gikai/member/\n",
      "Sending to GPT\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode characters in position 14-20: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\katok\\Projects\\kokkai_analysis\\data_prepping\\create_local_gov_json_data.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \t\u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m output \u001b[39m=\u001b[39m handle_reprs_on_single_page(city_dict, city_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwriting json\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\katok\\Projects\\kokkai_analysis\\data_prepping\\create_local_gov_json_data.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \t\u001b[39mif\u001b[39;00m response:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \t\toutput \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39;49m\u001b[39mmembers\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'members'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\katok\\Projects\\kokkai_analysis\\data_prepping\\create_local_gov_json_data.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \tcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/katok/Projects/kokkai_analysis/data_prepping/create_local_gov_json_data.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \tlogger\u001b[39m.\u001b[39;49mwrite(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCould not get \u001b[39;49m\u001b[39m{\u001b[39;49;00mcity_name\u001b[39m}\u001b[39;49;00m\u001b[39m : \u001b[39;49m\u001b[39m{\u001b[39;49;00mcity_dict[\u001b[39m'\u001b[39;49m\u001b[39murls\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\katok\\Projects\\kokkai_analysis\\data_prepping\\logger\\Logger.py:7\u001b[0m, in \u001b[0;36mLogger.write\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite\u001b[39m(\u001b[39mself\u001b[39m, message):\n\u001b[1;32m----> 7\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog\u001b[39m.\u001b[39;49mwrite(message)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_encode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,encoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode characters in position 14-20: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "scraping_resource_path = os.path.join(RESOURCE_DIR, 'local_gov_repr_scrape.json')\n",
    "scraping_resource = read_json(scraping_resource_path)\n",
    "for city_name, city_dict in scraping_resource.items():\n",
    "\tcity_dir = os.path.join(LOCAL_GOV_MEMBER_DIR, city_name)\n",
    "\tos.makedirs(city_dir, exist_ok=True)\n",
    "\tif os.path.exists(os.path.join(city_dir, 'members.json')):\n",
    "\t\tcontinue\n",
    "\tcount = 1\n",
    "\tprint(f\"Getting {city_name} data [{count}]\")\n",
    "\twhile True:\n",
    "\t\tif count == 3:\n",
    "\t\t\tbreak\n",
    "\t\ttry:\n",
    "\t\t\tprofile_on_multiple_pages = 'multiple_pages' in city_dict.keys()\n",
    "\t\t\tif profile_on_multiple_pages:\n",
    "\t\t\t\toutput = handle_reprs_on_multiple_pages(city_dict, city_name)\n",
    "\t\t\t\tprint('writing json')\n",
    "\t\t\t\twrite_json([{\"members\":output}], os.path.join(city_dir, 'members.json'))\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tscrapable = city_dict['reprs_xpath'] != ''\n",
    "\t\t\tif not scrapable:\n",
    "\t\t\t\tbreak\n",
    "\t\t\toutput = handle_reprs_on_single_page(city_dict, city_name)\n",
    "\t\t\tprint('writing json')\n",
    "\t\t\twrite_json({\"members\":output}, os.path.join(city_dir, 'members.json'))\n",
    "\t\t\tbreak\n",
    "\t\texcept:\n",
    "\t\t\tcount += 1\n",
    "\t\t\tlogger.write(f\"Could not get {city_name} : {city_dict['urls']}\\n\")\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting one sample for the city\n",
    "city = \"北海道　札幌市\"\n",
    "gs.get_url(scraping_resource[city]['urls'][0])\n",
    "reprs_component = gs.get_site_components_by(By.XPATH, scraping_resource[city]['reprs_xpath'])\n",
    "all_text = reprs_component[0].text\n",
    "file = open(os.path.join(RESOURCE_DIR, 'sample_text.txt'), 'w', encoding='utf-8')\n",
    "file.write(all_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kokkaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
